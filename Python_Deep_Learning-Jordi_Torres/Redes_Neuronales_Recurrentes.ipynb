{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Recurrentes (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vectorización de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['me' 'gusta' 'el' 'deep' 'learning']\n",
      "[4 2 1 0 3]\n",
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pepel\\.conda\\envs\\PySpace310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "doc = \"Me gusta el Deep Learning\"\n",
    "\n",
    "doc = doc.lower()\n",
    "doc = doc.split()\n",
    "values = array(doc)\n",
    "print(values)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Embedding layer de Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Programando una RNN: Generación de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Descarga y preprocesado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 203251 caráceters\n",
      "El texto está compuesto de estos 92 caráceteres:\n",
      "\n",
      "['\\n', '\\r', ' ', '!', '\"', '#', '%', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xad', 'ÿ', 'Š', '‡', '…']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path_txt = os.path.join(\"DeepLearning-Introduccion-practica-con-Keras-PRIMERA-PARTE.txt\")\n",
    "\n",
    "text = open(path_txt, 'rb').read().decode(encoding='utf-8')\n",
    "print(\"Longitud del texto: {} caráceters\".format(len(text)))\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "print(\"El texto está compuesto de estos {} caráceteres:\".format(len(vocab)))\n",
    "print(f\"\\n{vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "char2dix = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " '\\n':   0,\n",
      " '\\r':   1,\n",
      " ' ' :   2,\n",
      " '!' :   3,\n",
      " '\"' :   4,\n",
      " '#' :   5,\n",
      " '%' :   6,\n",
      " \"'\" :   7,\n",
      " '(' :   8,\n",
      " ')' :   9,\n",
      " '*' :  10,\n",
      " '+' :  11,\n",
      " ',' :  12,\n",
      " '-' :  13,\n",
      " '.' :  14,\n",
      " '/' :  15,\n",
      " '0' :  16,\n",
      " '1' :  17,\n",
      " '2' :  18,\n",
      " '3' :  19,\n",
      " '4' :  20,\n",
      " '5' :  21,\n",
      " '6' :  22,\n",
      " '7' :  23,\n",
      " '8' :  24,\n",
      " '9' :  25,\n",
      " ':' :  26,\n",
      " ';' :  27,\n",
      " '<' :  28,\n",
      " '=' :  29,\n",
      " '>' :  30,\n",
      " '?' :  31,\n",
      " '@' :  32,\n",
      " 'A' :  33,\n",
      " 'B' :  34,\n",
      " 'C' :  35,\n",
      " 'D' :  36,\n",
      " 'E' :  37,\n",
      " 'F' :  38,\n",
      " 'G' :  39,\n",
      " 'H' :  40,\n",
      " 'I' :  41,\n",
      " 'J' :  42,\n",
      " 'K' :  43,\n",
      " 'L' :  44,\n",
      " 'M' :  45,\n",
      " 'N' :  46,\n",
      " 'O' :  47,\n",
      " 'P' :  48,\n",
      " 'Q' :  49,\n",
      " 'R' :  50,\n",
      " 'S' :  51,\n",
      " 'T' :  52,\n",
      " 'U' :  53,\n",
      " 'V' :  54,\n",
      " 'W' :  55,\n",
      " 'X' :  56,\n",
      " 'Y' :  57,\n",
      " '[' :  58,\n",
      " ']' :  59,\n",
      " '_' :  60,\n",
      " 'a' :  61,\n",
      " 'b' :  62,\n",
      " 'c' :  63,\n",
      " 'd' :  64,\n",
      " 'e' :  65,\n",
      " 'f' :  66,\n",
      " 'g' :  67,\n",
      " 'h' :  68,\n",
      " 'i' :  69,\n",
      " 'j' :  70,\n",
      " 'k' :  71,\n",
      " 'l' :  72,\n",
      " 'm' :  73,\n",
      " 'n' :  74,\n",
      " 'o' :  75,\n",
      " 'p' :  76,\n",
      " 'q' :  77,\n",
      " 'r' :  78,\n",
      " 's' :  79,\n",
      " 't' :  80,\n",
      " 'u' :  81,\n",
      " 'v' :  82,\n",
      " 'w' :  83,\n",
      " 'x' :  84,\n",
      " 'y' :  85,\n",
      " 'z' :  86,\n",
      " '\\xad':  87,\n",
      " 'ÿ' :  88,\n",
      " 'Š' :  89,\n",
      " '‡' :  90,\n",
      " '…' :  91,\n"
     ]
    }
   ],
   "source": [
    "for char, _ in zip(char2dix, range(len(vocab))):\n",
    "    print(\" {:4s}: {:3d},\".format(repr(char), char2dix[char]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int = np.array([char2dix[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texto: 'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fun'\n",
      "array([48, 78, 75, 72, 75, 67, 75,  1,  0, 37, 74,  2, 17, 25, 21, 19, 12,\n",
      "        2, 41, 79, 61, 61, 63,  2, 33, 79, 69, 73, 75, 82,  2, 76, 81, 62,\n",
      "       72, 69, 63, 75,  2, 51, 65, 67, 81, 74, 64, 61,  2, 38, 81, 74])\n"
     ]
    }
   ],
   "source": [
    "print(\"texto: {}\".format(repr(text[:50])))\n",
    "print(\"{}\".format(repr(text_as_int[:50])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Preparación de los datos para ser usados por la RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "seq_length = 100\n",
    "\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n",
      "'(o el decimotercero segun otras fuentes, este es un tema de debate). En Segunda Fundacion aparece por'\n",
      "' primera vez Arkady Darell, uno de los principales personajes de la parte final de la saga. En su pri'\n",
      "'mera escena, Arkady, que tiene 14 anos, esta haciendo sus tareas escolares. En concreto, una redaccio'\n",
      "'n que lleva por titulo ?El Futuro del Plan Sheldon?. Para hacer la redaccion, Arkady esta utilizando '\n",
      "'un ?transcriptor?,un dispositivo que convierte su voz en palabras escritas. Este tipo de dispositivo,'\n",
      "' que para Isaac Asimov era ciencia ficcion en 1953, lo tenemos al alcance de la mano en la mayoria de'\n",
      "' nuestros smartphones, y el Deep Learning es uno de los responsables de que ya tengamos este tipo de '\n",
      "'aplicaciones, siendo la tecnologia otro de ellos.En la actualidad disponemos de GPUs (Graphics Proces'\n",
      "'sor Units), que solo cuestan alrededor de 100 euros, que estarian en la lista del Top500 hace unos po'\n"
     ]
    }
   ],
   "source": [
    "for item in sequences.take(10):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Prologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion'\n",
      "Target data:  'rologo\\r\\nEn 1953, Isaac Asimov publico Segunda Fundacion, el tercer libro de la saga de la Fundacion '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input data: \", repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print(\"Target data: \", repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int32, name=None), TensorSpec(shape=(100,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Construcción del modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    ))\n",
    "    model.add(LSTM(\n",
    "        rnn_units,\n",
    "        return_sequences=True,\n",
    "        stateful=True,\n",
    "        recurrent_initializer='glorot_uniform'\n",
    "    ))\n",
    "    model.add(Dense(vocab_size))\n",
    "    return model\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           23552     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 92)            94300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,364,828\n",
      "Trainable params: 5,364,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (64, 100) # (batch_size, sequence_length)\n",
      "Target: (64, 100) # (batch_size, sequence_length)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(\"Input:\", input_example_batch.shape, \"# (batch_size, sequence_length)\")\n",
    "    print(\"Target:\", target_example_batch.shape, \"# (batch_size, sequence_length)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  (64, 100, 92) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(\"Prediction: \", example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(\n",
    "    example_batch_predictions[0],\n",
    "    num_samples=1)\n",
    "\n",
    "sampled_indices_characters = tf.squeeze(\n",
    "    sampled_indices,\n",
    "    axis=-1\n",
    ").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90 68 44 86 45 51 66 86 31 65 66 60 58 27 65 15 34 11 30 23 70 61 16 82\n",
      " 39 88 24 52 49 77 14 66 70 91 83  8 80  3 59 37 39 78 62 79 47 78 24 18\n",
      " 47 21 82 54 53  8  7 91 39 67 40 82 44 48 84 30 50 91 48  6 35 31 73 72\n",
      " 48 37 30 43 52 89 36 36 19 10  3 37 30 10 39 41 12 16 32 44 34 78 34  3\n",
      " 32 31 64 44]\n"
     ]
    }
   ],
   "source": [
    "print(sampled_indices_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Entrenamiento del modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Generación de texto usando el modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Generando texto falso de Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpace310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
