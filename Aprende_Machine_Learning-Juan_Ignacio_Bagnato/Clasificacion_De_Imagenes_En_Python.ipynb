{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Imágenes en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU\n",
    "from keras.optimizers import Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo imágenes de c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\\n",
      "c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\americano 1\n",
      "c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\basket 9348\n",
      "c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\beisball 8823\n",
      "c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\boxeo 7752\n",
      "c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\ciclismo 7125\n",
      "c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\f1 7533\n",
      "c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\futbol 5053\n",
      "c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\golf 7617\n",
      "c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\natacion 9768\n",
      "c:\\Mis Proyectos\\Git\\Books\\Aprende_Machine_Learning-Juan_Ignacio_Bagnato\\..\\..\\sportimages\\tenis 5172\n",
      "Directorios leídos: 10\n",
      "Imágenes en cada directorio: [9349, 8823, 7752, 7125, 7533, 5053, 7617, 9768, 5172, 8936]\n",
      "Suma total de imágenes en subdirectorios: 77128\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.join(os.getcwd(), '..', '..', 'sportimages')\n",
    "imgpath = dirname + os.sep\n",
    "\n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot = ''\n",
    "cant = 0\n",
    "\n",
    "print(\"Leyendo imágenes de\", imgpath)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant += 1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images.append(image)\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print(b, end=\"\\r\")\n",
    "            if prevRoot != root:\n",
    "                print(root, cant)\n",
    "                prevRoot = root\n",
    "                directories.append(root)\n",
    "                dircount.append(cant)\n",
    "                cant = 0\n",
    "dircount.append(cant)\n",
    "\n",
    "dircount = dircount[1:]\n",
    "dircount[0] = dircount[0] + 1\n",
    "print(\"Directorios leídos:\", len(directories))\n",
    "print(\"Imágenes en cada directorio:\", dircount)\n",
    "print(\"Suma total de imágenes en subdirectorios:\", sum(dircount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crear etiquetas y clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de etiquetas creadas: 77128\n",
      "0 americano\n",
      "1 basket\n",
      "2 beisball\n",
      "3 boxeo\n",
      "4 ciclismo\n",
      "5 f1\n",
      "6 futbol\n",
      "7 golf\n",
      "8 natacion\n",
      "9 tenis\n",
      "Total number of outputs: 10\n",
      "Output classes: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "indice = 0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice += 1\n",
    "print(\"Cantidad de etiquetas creadas:\", len(labels))\n",
    "\n",
    "deportes = []\n",
    "indice = 0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice, name[len(name)-1])\n",
    "    deportes.append(name[len(name)-1])\n",
    "    indice += 1\n",
    "\n",
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8)\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print(\"Total number of outputs:\", nClasses)\n",
    "print(\"Output classes:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creamos sets de entrenamiento y test, validación y preprocesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (61702, 21, 28, 3), (61702,)\n",
      "Test data shape: (15426, 21, 28, 3), (15426,)\n",
      "Original label: 6\n",
      "After conversion to one-hot: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "(49361, 21, 28, 3) (12341, 21, 28, 3) (49361, 10) (12341, 10)\n"
     ]
    }
   ],
   "source": [
    "# Mezclar todo y crear los grupos de entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(f\"Train data shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "# Change the labels from categorical to one-hot encoding\n",
    "y_train_ohe = to_categorical(y_train)\n",
    "y_test_ohe = to_categorical(y_test)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print(\"Original label:\", y_train[0])\n",
    "print(\"After conversion to one-hot:\", y_train_ohe[0])\n",
    "\n",
    "X_train, X_valid, train_label, valid_label = train_test_split(X_train, y_train_ohe, test_size=0.2, random_state=13)\n",
    "\n",
    "print(X_train.shape, X_valid.shape, train_label.shape, valid_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creamos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 21, 28, 32)        896       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 21, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 11, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11, 14, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4928)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                157728    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 158,954\n",
      "Trainable params: 158,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 6\n",
    "batch_size = 64\n",
    "\n",
    "sport_model = Sequential()\n",
    "sport_model.add(Conv2D(\n",
    "    32,\n",
    "    kernel_size=(3, 3),\n",
    "    activation='linear',\n",
    "    padding='same',\n",
    "    input_shape=(21, 28, 3)\n",
    "))\n",
    "sport_model.add(LeakyReLU(alpha=0.1))\n",
    "sport_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "sport_model.add(Dropout(0.5))\n",
    "\n",
    "sport_model.add(Flatten())\n",
    "sport_model.add(Dense(32, activation='linear'))\n",
    "sport_model.add(LeakyReLU(alpha=0.1))\n",
    "sport_model.add(Dropout(0.5))\n",
    "sport_model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "sport_model.summary()\n",
    "\n",
    "sport_model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=Adagrad(learning_rate=INIT_LR, decay=INIT_LR/100),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entrenamos la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "772/772 [==============================] - 7s 3ms/step - loss: 2.1435 - accuracy: 0.2314 - val_loss: 1.8546 - val_accuracy: 0.5337\n",
      "Epoch 2/6\n",
      "772/772 [==============================] - 2s 2ms/step - loss: 1.8054 - accuracy: 0.3873 - val_loss: 1.5022 - val_accuracy: 0.5917\n",
      "Epoch 3/6\n",
      "772/772 [==============================] - 2s 3ms/step - loss: 1.5863 - accuracy: 0.4668 - val_loss: 1.2860 - val_accuracy: 0.6121\n",
      "Epoch 4/6\n",
      "772/772 [==============================] - 2s 3ms/step - loss: 1.4401 - accuracy: 0.5146 - val_loss: 1.1509 - val_accuracy: 0.6576\n",
      "Epoch 5/6\n",
      "772/772 [==============================] - 2s 3ms/step - loss: 1.3414 - accuracy: 0.5461 - val_loss: 1.0609 - val_accuracy: 0.6807\n",
      "Epoch 6/6\n",
      "772/772 [==============================] - 2s 2ms/step - loss: 1.2794 - accuracy: 0.5693 - val_loss: 0.9958 - val_accuracy: 0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sports_mnist.h5py\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sports_mnist.h5py\\assets\n"
     ]
    }
   ],
   "source": [
    "sport_train_dropout = sport_model.fit(\n",
    "    X_train,\n",
    "    train_label,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_valid, valid_label)\n",
    ")\n",
    "\n",
    "# Guardamos la red para reutilizarla en el futuro, sin tener que volverla a entrenar\n",
    "sport_model.save(\"sports_mnist.h5py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resultados de la clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 1s 1ms/step - loss: 1.0087 - accuracy: 0.7128\n",
      "Test loss: 1.0086722373962402\n",
      "Test accuracy: 0.7127577066421509\n"
     ]
    }
   ],
   "source": [
    "test_eval = sport_model.evaluate(X_test, y_test_ohe, verbose=1)\n",
    "\n",
    "print(\"Test loss:\", test_eval[0])\n",
    "print(\"Test accuracy:\", test_eval[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpace310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
